{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will load the model information, generate the model definition, and run the model estimation using FSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nipype.algorithms.modelgen as model   # model generation\n",
    "from  nipype.interfaces import fsl, ants      \n",
    "from nipype.interfaces.base import Bunch\n",
    "import os,json,glob\n",
    "import numpy\n",
    "import nibabel\n",
    "import nilearn.plotting\n",
    "\n",
    "from make_event_files_from_json import MakeEventFilesFromJSON\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "try:\n",
    "    datadir=os.environ['FMRIDATADIR']\n",
    "    assert not datadir==''\n",
    "except:\n",
    "    datadir='/Users/poldrack/data_unsynced/myconnectome/sub00001'\n",
    "    \n",
    "results_dir = os.path.abspath(\"../results\")\n",
    "if not os.path.exists(results_dir):\n",
    "    os.mkdir(results_dir)\n",
    "\n",
    "from nipype.caching import Memory\n",
    "mem = Memory(base_dir='.')\n",
    "\n",
    "print 'Using data from',datadir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the scan and model info, and generate the event files for FSL from the information in model.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subject='sub00001'\n",
    "session='ses014'  \n",
    "# note - we have to use the anatomy from a different session'\n",
    "subdir=os.path.join(datadir,'ds031', subject, session)\n",
    "tasknum=2 # n-back\n",
    "\n",
    "preprocessed_epi = os.path.join(results_dir, \"preprocessed_epi_native_space.nii\")\n",
    "\n",
    "scaninfo=json.load(open(os.path.join(subdir,\n",
    "        'functional/sub00001_ses014_task002_run001_bold.json')))\n",
    "tr=scaninfo['RepetitionTime']\n",
    "\n",
    "modelfile=os.path.join(subdir,'model.json')\n",
    "modelinfo=json.load(open(modelfile))\n",
    "taskinfo=modelinfo['task%03d'%tasknum]['model001']\n",
    "evs=taskinfo['Variables']\n",
    "contrasts=taskinfo['Contrasts']\n",
    "\n",
    "# get the response onsets\n",
    "response_onsets=[]\n",
    "\n",
    "for v in evs.iterkeys():\n",
    "\n",
    "    if evs[v]['VariableName'].find('_target_ons')>-1:\n",
    "        for ons in evs[v]['onsets']:\n",
    "            response_onsets.append(ons[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the model.  For the sake of speed we will use a simplified model that treats the study as a blocked design rather than modeling each item separately, but we also model instructions and motor responses; this, it is a hybrid block/event-related design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "instruction_onsets=list(numpy.array([68,176,372,2,154,416,24,220,350,112,198,328,46,264,394,90,242,306])-2.0)\n",
    "\n",
    "info = [Bunch(conditions=['faces-1back',\n",
    "                          'faces-2back',\n",
    "                          'scenes-1back',\n",
    "                          'scenes-2back',\n",
    "                          'chars-1back',\n",
    "                          'chars-2back',\n",
    "                          'instructions',\n",
    "                          'responses'],\n",
    "              onsets=[[68,176,372],\n",
    "                      [2,154,416],\n",
    "                      [24,220,350],\n",
    "                      [112,198,328],\n",
    "                      [46,264,394],\n",
    "                      [90,242,306],\n",
    "                      instruction_onsets,\n",
    "                      response_onsets],\n",
    "              durations=[[20],\n",
    "                         [20],\n",
    "                         [20],\n",
    "                         [20],\n",
    "                         [20],\n",
    "                         [20],\n",
    "                         [2],\n",
    "                         [1]])\n",
    "       ]\n",
    "\n",
    "s = model.SpecifyModel()\n",
    "s.inputs.input_units = 'secs'\n",
    "s.inputs.functional_runs = preprocessed_epi\n",
    "s.inputs.time_repetition = tr\n",
    "s.inputs.high_pass_filter_cutoff = 128.\n",
    "s.inputs.subject_info = info\n",
    "specify_model_results = s.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the fsf and ev files using Level1Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "contrasts=[['faces>Baseline','T', \n",
    "            ['faces-1back','faces-2back'],[0.5,0.5]],\n",
    "           ['scenes>Baseline','T', \n",
    "            ['scenes-1back','scenes-2back'],[0.5,0.5]],\n",
    "           ['chars>Baseline','T', \n",
    "            ['chars-1back','chars-2back'],[0.5,0.5]],\n",
    "           ['2back>1back','T', \n",
    "            ['faces-1back','faces-2back','scenes-1back','scenes-2back','chars-1back','chars-2back'],[-1,1,-1,1,-1,1,-1,1]],\n",
    "          ['response>Baseline','T',\n",
    "           ['responses'],[1]],\n",
    "          ['instructions>Baseline','T',\n",
    "           ['instructions'],[1]]]\n",
    "           \n",
    "level1design = mem.cache(fsl.model.Level1Design)\n",
    "level1design_results = level1design(interscan_interval = tr,\n",
    "                                    bases = {'dgamma':{'derivs': True}},\n",
    "                                    session_info = specify_model_results.outputs.session_info,\n",
    "                                    model_serial_correlations=True,\n",
    "                                    contrasts=contrasts)\n",
    "\n",
    "level1design_results.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the full set of model files using FEATModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelgen = mem.cache(fsl.model.FEATModel)\n",
    "modelgen_results = modelgen(fsf_file=level1design_results.outputs.fsf_files,\n",
    "                            ev_files=level1design_results.outputs.ev_files)\n",
    "modelgen_results.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the design matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "desmtx=numpy.loadtxt(modelgen_results.outputs.design_file,skiprows=5)\n",
    "plt.imshow(desmtx,aspect='auto',interpolation='nearest',cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the correlation matrix for design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cc=numpy.corrcoef(desmtx.T)\n",
    "plt.imshow(cc,aspect='auto',interpolation='nearest', cmap=plt.cm.cubehelix_r)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate the model using FILMGLS - this will take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = mem.cache(fsl.maths.ApplyMask)\n",
    "mask_results = mask(in_file=preprocessed_epi,\n",
    "                    mask_file=os.path.join(results_dir, \"mask.nii.gz\"))\n",
    "mask_results.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filmgls = mem.cache(fsl.FILMGLS)\n",
    "filmgls_results = filmgls(in_file=mask_results.outputs.out_file,\n",
    "                          design_file = modelgen_results.outputs.design_file,\n",
    "                          tcon_file = modelgen_results.outputs.con_file,\n",
    "                          autocorr_noestimate = True)\n",
    "filmgls_results.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "meanimg=nibabel.load(os.path.join(results_dir, \"meanbold.nii.gz\"))\n",
    "\n",
    "for contrast_i in range(len(contrasts)):\n",
    "    nilearn.plotting.plot_stat_map(filmgls_results.outputs.zstats[contrast_i], meanimg,\n",
    "                                   title='Contrast %d: %s'%(contrast_i,contrasts[contrast_i][0]),\n",
    "                                   threshold=2.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Move copes, varcopes, and the mask into MNI space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the group level analysis we need to move results from all subjects into one common MNI space. Let's start with the EPI derived mask (we will use it later for group level mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask_file = os.path.join(results_dir, \"mask.nii.gz\")\n",
    "epi_to_t1_warp = os.path.join(results_dir, \"epi_to_t1_warp.nii.gz\")\n",
    "t1_to_mni_warp = os.path.join(results_dir, \"t1_to_mni_warp.h5\")\n",
    "in_file = mask_file\n",
    "anat_subject='ses018'\n",
    "anatomydir=os.path.join(datadir,'ds031/sub00001',anat_subject,\n",
    "        'anatomy')\n",
    "t1_file = os.path.join(anatomydir,'sub00001_ses018_T1w_001.nii.gz')\n",
    "\n",
    "epi_to_t1 = mem.cache(fsl.ApplyWarp)\n",
    "epi_to_t1_mask_results = epi_to_t1(in_file=in_file,\n",
    "                                   ref_file=t1_file,\n",
    "                                   field_file=epi_to_t1_warp,\n",
    "                                   interp=\"nn\")\n",
    "nilearn.plotting.plot_roi(epi_to_t1_mask_results.outputs.out_file, title=\"EPI mask in subject T1 space\")\n",
    "\n",
    "t1_to_mni = mem.cache(ants.ApplyTransforms)\n",
    "t1_to_mni_mask_results = t1_to_mni(input_image=epi_to_t1_mask_results.outputs.out_file,\n",
    "                                   reference_image=os.path.join(os.getenv('FSLDIR'),'data/standard/MNI152_T1_2mm_brain.nii.gz'),\n",
    "                                   transforms=t1_to_mni_warp,\n",
    "                                   interpolation=\"NearestNeighbor\")\n",
    "t1_to_mni_mask_results.outputs\n",
    "nilearn.plotting.plot_roi(t1_to_mni_mask_results.outputs.output_image, title=\"EPI mask in MNI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the same procedure for all of the contrast and variance images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for image in filmgls_results.outputs.copes + filmgls_results.outputs.varcopes:\n",
    "    _, fname = os.path.split(image)\n",
    "    epi_to_t1_results = epi_to_t1(in_file=image,\n",
    "                                       ref_file=t1_file,\n",
    "                                       field_file=epi_to_t1_warp,\n",
    "                                       interp=\"spline\")\n",
    "\n",
    "    t1_to_mni_results = t1_to_mni(input_image=epi_to_t1_results.outputs.out_file,\n",
    "                                  reference_image=os.path.join(os.getenv('FSLDIR'),'data/standard/MNI152_T1_2mm_brain.nii.gz'),\n",
    "                                  transforms=t1_to_mni_warp,\n",
    "                                  interpolation=\"BSpline\")\n",
    "    nilearn.plotting.plot_stat_map(t1_to_mni_results.outputs.output_image, title=\"%s in MNI\"%fname, threshold='auto')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}