{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will decode orientation using data collected for the class.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using data from orientation_data\n"
     ]
    }
   ],
   "source": [
    "import nipype.algorithms.modelgen as model   # model generation\n",
    "import nipype.interfaces.fsl as fsl          # fsl\n",
    "from nipype.interfaces.base import Bunch\n",
    "import os,json,glob\n",
    "import numpy\n",
    "import nibabel\n",
    "import nilearn.plotting\n",
    "import sklearn.multiclass\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.metrics\n",
    "import sklearn.cross_validation\n",
    "from nilearn.input_data import NiftiMasker\n",
    "import scipy.stats\n",
    "import random\n",
    "import nilearn.datasets\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "datadir='orientation_data'\n",
    "\n",
    "print('using data from %s'%datadir)\n",
    "\n",
    "def get_orientation_data(datadir):\n",
    "    groups=['All','V1','V2','V3']\n",
    "    data={}\n",
    "    for g in groups:\n",
    "        yfile=os.path.join(datadir,'%s_groups.txt'%g)\n",
    "        xfile=os.path.join(datadir,'%s_instances.txt'%g)\n",
    "        data[g]={'X':numpy.loadtxt(xfile),'Y':numpy.loadtxt(yfile)}\n",
    "    return data\n",
    "odata=get_orientation_data(datadir)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a simple classifier using balanced 8-fold crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'V3': 0.50993377483443714, 'V2': 0.60264900662251653, 'All': 0.60927152317880795, 'V1': 0.55629139072847678}\n"
     ]
    }
   ],
   "source": [
    "def run_classifier(odata, shuffle=False,nfolds=8):\n",
    "    groups=['All','V1','V2','V3']\n",
    "    acc={}\n",
    "    for g in groups:\n",
    "        features=odata[g]['X']\n",
    "        labels=odata[g]['Y'].copy()\n",
    "        if shuffle:\n",
    "            numpy.random.shuffle(labels)\n",
    "        skf = sklearn.cross_validation.StratifiedKFold(labels, 8)\n",
    "        pred=numpy.zeros(labels.shape[0])\n",
    "        for train, test in skf:\n",
    "            clf=sklearn.svm.SVC()\n",
    "            clf.fit(features[train,:],labels[train])\n",
    "            pred[test]=clf.predict(features[test,:])\n",
    "        acc[g]=sklearn.metrics.accuracy_score(labels, pred)\n",
    "    return acc\n",
    "\n",
    "acc=run_classifier(odata)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see if this is better than we would predict by chance.  we will do this by randomly shuffling the labels and recording the accuracy score for each random run, and then comparing our actual score to that null distribution.  \n",
    "\n",
    "NOTE: This will take a few minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "groups=['All','V1','V2','V3']\n",
    "nruns=1000\n",
    "rand_acc=numpy.zeros((nruns,4))\n",
    "for r in range(nruns):\n",
    "    tmp=run_classifier(odata,shuffle=True)\n",
    "    rand_acc[r,:]=[tmp['All'],tmp['V1'],tmp['V2'],tmp['V3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All voxels: 0.609 (p=0.000)\n",
      "V1 voxels: 0.556 (p=0.000)\n",
      "V2 voxels: 0.603 (p=0.000)\n",
      "V3 voxels: 0.510 (p=1.000)\n"
     ]
    }
   ],
   "source": [
    "mean_acc=numpy.mean(rand_acc,0)\n",
    "\n",
    "for i in range(len(groups)):\n",
    "    print('%s voxels: %0.3f (p=%0.3f)'%(groups[i],acc[groups[i]],\n",
    "                    1-scipy.stats.percentileofscore(rand_acc[i,:],acc[groups[i]])/100.))\n"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
