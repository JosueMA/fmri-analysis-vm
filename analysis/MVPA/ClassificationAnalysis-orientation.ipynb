{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will decode orientation using data collected for the class.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using data from orientation_data\n"
     ]
    }
   ],
   "source": [
    "import os,json,glob\n",
    "import numpy\n",
    "import nibabel\n",
    "import sklearn.multiclass\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.metrics\n",
    "import sklearn.cross_validation\n",
    "import sklearn.preprocessing\n",
    "import scipy.stats\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "datadir='orientation_data'\n",
    "\n",
    "print('using data from %s'%datadir)\n",
    "\n",
    "def get_orientation_data(datadir):\n",
    "    groups=['All','V1','V2','V3']\n",
    "    data={}\n",
    "    for g in groups:\n",
    "        yfile=os.path.join(datadir,'%s_groups.txt'%g)\n",
    "        xfile=os.path.join(datadir,'%s_instances.txt'%g)\n",
    "        data[g]={'X':numpy.loadtxt(xfile),'Y':numpy.loadtxt(yfile)}\n",
    "    return data\n",
    "\n",
    "odata=get_orientation_data(datadir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a simple classifier using balanced 8-fold crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'All': 0.66887417218543044, 'V1': 0.64238410596026485, 'V3': 0.6887417218543046, 'V2': 0.61589403973509937}\n"
     ]
    }
   ],
   "source": [
    "def run_classifier(odata, shuffle=False,nfolds=8,C=1,scale=True):\n",
    "    groups=['All','V1','V2','V3']\n",
    "    acc={}\n",
    "    for g in groups:\n",
    "        features=odata[g]['X']\n",
    "        if scale:\n",
    "            features=sklearn.preprocessing.scale(features)\n",
    "        labels=odata[g]['Y'].copy()\n",
    "        if shuffle:\n",
    "            numpy.random.shuffle(labels)\n",
    "        skf = sklearn.cross_validation.StratifiedKFold(labels, 8)\n",
    "        pred=numpy.zeros(labels.shape[0])\n",
    "        for train, test in skf:\n",
    "            clf=sklearn.svm.SVC(C=C)\n",
    "            clf.fit(features[train,:],labels[train])\n",
    "            pred[test]=clf.predict(features[test,:])\n",
    "        acc[g]=sklearn.metrics.accuracy_score(labels, pred)\n",
    "    return acc\n",
    "\n",
    "C=10\n",
    "\n",
    "acc=run_classifier(odata,C=C)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see if this is better than we would predict by chance.  we will do this by randomly shuffling the labels and recording the accuracy score for each random run, and then comparing our actual score to that null distribution.  \n",
    "\n",
    "NOTE: This will take a few minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "groups=['All','V1','V2','V3']\n",
    "nruns=1000\n",
    "rand_acc=numpy.zeros((nruns,4))\n",
    "for r in range(nruns):\n",
    "    tmp=run_classifier(odata,shuffle=True,C=C)\n",
    "    rand_acc[r,:]=[tmp['All'],tmp['V1'],tmp['V2'],tmp['V3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All voxels: 0.669 (p=0.000)\n",
      "V1 voxels: 0.642 (p=0.000)\n",
      "V2 voxels: 0.616 (p=0.000)\n",
      "V3 voxels: 0.689 (p=0.000)\n"
     ]
    }
   ],
   "source": [
    "mean_acc=numpy.mean(rand_acc,0)\n",
    "\n",
    "for i in range(len(groups)):\n",
    "    print('%s voxels: %0.3f (p=%0.3f)'%(groups[i],acc[groups[i]],\n",
    "                    1-scipy.stats.percentileofscore(rand_acc[i,:],acc[groups[i]])/100.))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__: Compare our results to those reported by Harrison & Tong.  How do they compare, and why do you think they might be different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
