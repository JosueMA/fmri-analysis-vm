{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides an introduction to the basic concepts of machine learning.\n",
    "\n",
    "Let's start by generating some data to work with.  Let's say that we have a dataset that has tested people on two continuous measures (processing speed and age) and one discrete measure (diagnosis with any psychiatric disorder).  First let's create the continuous data assuming that there is a relationship between these two variables.  We will make a function to generate a new dataset, since we will need to do this multiple times."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "\n",
    "def make_continuous_data(mean=[45,100],var=[10,10],cor=-0.6,N=100):\n",
    "    \"\"\"\n",
    "    generate a synthetic data set with two variables\n",
    "    \"\"\"\n",
    "    cor=numpy.array([[1.,cor],[cor,1.]])\n",
    "    var=numpy.array([[var[0],0],[0,var[1]]])\n",
    "    cov=var.dot(cor).dot(var)\n",
    "    return numpy.random.multivariate_normal(mean,cov,N)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n=25\n",
    "d=make_continuous_data(N=n)\n",
    "plt.scatter(d[:,0],d[:,1])\n",
    "plt.xlabel('age')\n",
    "plt.ylabel('processing speed')\n",
    "print 'R-squared:',numpy.corrcoef(d.T)[0,1]**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the simplest story that we could tell about these data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean=numpy.mean(d,0)\n",
    "print mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a relation between processing speed and age? Compute the linear regression equation to find out. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slope,intercept,r,p,se=scipy.stats.linregress(d[:,0],d[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'processing speed = %f + %f*age'%(intercept,slope)\n",
    "print 'p =',p\n",
    "\n",
    "def get_RMSE(y,pred):\n",
    "    return numpy.sqrt(numpy.mean((y - pred)**2))\n",
    "\n",
    "def get_R2(y,pred):\n",
    "    \"\"\" compute r-squared\"\"\"\n",
    "    return numpy.corrcoef(y,pred)[0,1]**2\n",
    "\n",
    "ax=plt.scatter(d[:,0],d[:,1])\n",
    "plt.xlabel('age')\n",
    "plt.ylabel('processing speed')\n",
    "plt.plot(d[:,0], slope * d[:,0] + intercept, color='red')\n",
    "# plot residual lines\n",
    "d_predicted=slope*d[:,0] + intercept\n",
    "for i in range(d.shape[0]):\n",
    "    x=d[i,0]\n",
    "    y=d[i,1]\n",
    "    plt.plot([x,x],[d_predicted[i],y],color='blue')\n",
    "\n",
    "RMSE=get_RMSE(d[:,1],d_predicted)\n",
    "rsq=get_R2(d[:,1],d_predicted)\n",
    "print 'rsquared=',rsq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows us that linear regression can provide a simple description of a complex dataset - we can describe the entire dataset in 2 numbers. Now let's ask how good this description is for a new dataset generated by the same process:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_new=make_continuous_data(N=n)\n",
    "d_new_predicted=intercept + slope*d[:,0]\n",
    "RMSE_new=get_RMSE(d_new[:,1],d_new_predicted)\n",
    "rsq_new=get_R2(d_new[:,1],d_new_predicted)\n",
    "print 'R2 for new data:',rsq_new\n",
    "\n",
    "ax=plt.scatter(d_new[:,0],d_new[:,1])\n",
    "plt.xlabel('age')\n",
    "plt.ylabel('processing speed')\n",
    "plt.plot(d_new[:,0], slope * d_new[:,0] + intercept, color='red')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do this 100 times and look at how variable the fits are."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nruns=100\n",
    "slopes=numpy.zeros(nruns)\n",
    "intercepts=numpy.zeros(nruns)\n",
    "rsquared=numpy.zeros(nruns)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "\n",
    "for i in range(nruns):\n",
    "    data=make_continuous_data(N=n)\n",
    "    slopes[i],intercepts[i],_,_,_=scipy.stats.linregress(data[:,0],data[:,1])\n",
    "    ax.plot(data[:,0], slopes[i] * data[:,0] + intercepts[i], color='red')\n",
    "    rsquared[i]=numpy.corrcoef(data[:,1],intercept + slope*data[:,0])[0,1]**2\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Original R2:',rsq\n",
    "print 'Mean R2 for new datasets on original model:',numpy.mean(rsquared)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see if we can get a more reasonable estimate of our accuracy at predicting on a new sample, using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.cross_validation\n",
    "loo=sklearn.cross_validation.LeaveOneOut(n)\n",
    "\n",
    "slopes_loo=numpy.zeros(n)\n",
    "intercepts_loo=numpy.zeros(n)\n",
    "pred=numpy.zeros(n)\n",
    "\n",
    "data=make_continuous_data(N=n)\n",
    "ctr=0\n",
    "for train,test in loo:\n",
    "    slopes_loo[ctr],intercepts_loo[ctr],_,_,_=scipy.stats.linregress(data[train,0],data[train,1])\n",
    "    pred[ctr]=intercepts_loo[ctr] + slopes_loo[ctr]*data[test,0]\n",
    "    ctr+=1\n",
    "\n",
    "print 'R2 for leave-one-out prediction:',numpy.corrcoef(pred,data[:,1])[0,1]**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Run the preceding cell several times. How variable are the R2 estimates?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the effect of outliers on correlation and prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add an outlier\n",
    "data_null=make_continuous_data(N=n,cor=0.0)\n",
    "outlier_multiplier=2.0\n",
    "\n",
    "data=numpy.vstack((data_null,[numpy.max(data_null[:,0])*outlier_multiplier,\n",
    "                         numpy.max(data_null[:,1])*outlier_multiplier*-1]))\n",
    "plt.scatter(data[:,0],data[:,1])\n",
    "slope,intercept,r,p,se=scipy.stats.linregress(data[:,0],data[:,1])\n",
    "plt.plot([numpy.min(data[:,0]),intercept + slope*numpy.min(data[:,0])],\n",
    "         [numpy.max(data[:,0]),intercept + slope*numpy.max(data[:,0])])\n",
    "rsq_outlier=r**2\n",
    "print 'R2 for regression with outlier:',rsq_outlier"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loo=sklearn.cross_validation.LeaveOneOut(data.shape[0])\n",
    "\n",
    "pred_outlier=numpy.zeros(data.shape[0])\n",
    "\n",
    "ctr=0\n",
    "for train,test in loo:\n",
    "    s,i,_,_,_=scipy.stats.linregress(data[train,0],data[train,1])\n",
    "    pred_outlier[ctr]=i + s*data[test,0]\n",
    "    ctr+=1\n",
    "\n",
    "print 'R2 for leave-one-out prediction:',numpy.corrcoef(pred_outlier,data[:,1])[0,1]**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at model complexity.  "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=make_continuous_data(N=n)\n",
    "loo=sklearn.cross_validation.LeaveOneOut(n)\n",
    "\n",
    "\n",
    "npolyorders=5\n",
    "# fit models of increasing complexity\n",
    "plt.scatter(data[:,0],data[:,1])\n",
    "xp=numpy.linspace(numpy.min(data[:,0]),numpy.max(data[:,0]),100)\n",
    "\n",
    "for i in range(npolyorders):\n",
    "    f = numpy.polyfit(data[:,0], data[:,1], i)\n",
    "    p=numpy.poly1d(f)\n",
    "    plt.plot(xp,p(xp))\n",
    "    \n",
    "# compute in-sample and out-of-sample error using LOO\n",
    "pred=numpy.zeros((n,npolyorders))\n",
    "mean_trainerr=numpy.zeros(npolyorders)\n",
    "prederr=numpy.zeros(npolyorders)\n",
    "\n",
    "for i in range(npolyorders):\n",
    "    ctr=0\n",
    "    trainerr=numpy.zeros(n)\n",
    "    for train,test in loo:\n",
    "        f = numpy.polyfit(data[train,0], data[train,1], i)\n",
    "        p=numpy.poly1d(f)\n",
    "        trainerr[ctr]=numpy.sqrt(numpy.mean((data[train,1]-p(data[train,0]))**2))\n",
    "        pred[test,i]=p(data[test,0])\n",
    "        ctr+=1\n",
    "    mean_trainerr[i]=numpy.mean(trainerr)\n",
    "    prederr[i]=numpy.sqrt(numpy.mean((data[:,1]-pred[:,i])**2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(range(npolyorders),mean_trainerr)\n",
    "plt.plot(range(npolyorders),prederr,color='red')\n",
    "plt.xlabel('Polynomial order')\n",
    "plt.ylabel('root mean squared error')\n",
    "plt.legend(['training error','test error'],loc=2)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}